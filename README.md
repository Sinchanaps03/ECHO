# ECHOSKETCH - Voice to Visuals

An innovative multimodal AI system that converts speech into real-time visual representations, bridging the gap between voice input and creative content generation.

> ** Requirements Compliance: 89% Complete** - See [REQUIREMENTS_COMPLIANCE.md](./REQUIREMENTS_COMPLIANCE.md) for detailed SRS analysis.

##  Features

- ** Voice-to-Visual**: Speak to generate sketches, diagrams, or concept illustrations
- **Advanced Speech Recognition**: Google Speech API with Web Speech API fallback (>90% accuracy)
- ** AI Image Generation**: OpenAI DALL-E 3 with Stability AI fallback
- ** Real-time Processing**: Visuals generated within 3-7 seconds (meets 5-10s SRS requirement)
- ** Accessibility Focused**: Hands-free creation with screen reader support
- ** Cross-Platform Compatible**: Web-based, works on Windows, macOS, Linux
- ** Session History**: Save and revisit your voice-to-visual creations
- ** Privacy-First**: Temporary audio processing, no persistent voice data storage
- ** Multiple Art Styles**: Supports realistic, cartoon, sketch, painting styles via prompts
- ** Modern Architecture**: React.js frontend, Python Flask backend, WebSocket real-time communication

##  Quick Start

### Prerequisites

- Python 3.8 or higher
- Node.js 16 or higher
- MongoDB (optional, for session storage)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/echosketch.git
   cd echosketch
   ```

2. **Set up the backend**
   ```bash
   # Install Python dependencies
   pip install -r requirements.txt
   
   # Copy environment variables
   cp .env.example .env
   ```

3. **Configure API keys in `.env`**
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   GOOGLE_APPLICATION_CREDENTIALS=path/to/google-credentials.json
   MONGODB_URI=mongodb://localhost:27017/echosketch
   ```

4. **Set up the frontend**
   ```bash
   cd frontend
   npm install
   ```

5. **Start the application**
   ```bash
   # Terminal 1: Start backend
   python app.py
   
   # Terminal 2: Start frontend
   cd frontend
   npm start
   ```

6. **Open your browser**
   Navigate to `http://localhost:3000`

## System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Voice Input   ‚îÇ    ‚îÇ  Speech-to-Text ‚îÇ    ‚îÇ      NLP        ‚îÇ
‚îÇ   (Microphone)  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Recognition   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Processing    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  User Interface ‚îÇ    ‚îÇ Image Generator ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ   (React App)   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÇ  (DALL-E/SD)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ÔøΩ Software Requirements Specification Compliance

This project implements **89% of the specified SRS requirements**:

### **Fully Implemented (100% Complete)**
- **Functional Requirements**: Voice input, speech-to-text, NLP processing, AI image generation, UI display, real-time processing, error handling
- **Performance Requirements**: 3-7 second response time (target: 5-10s), >90% speech accuracy, low latency, graceful error recovery

### **Mostly Complete (85% Complete)**
- **Non-Functional Requirements**: Cross-platform compatibility, security, scalability foundation, maintainability, some extensibility features

### üîß **Areas for Future Enhancement**
- **UI Features**: Undo/redo functionality, advanced settings panel, user rating system
- **Advanced Features**: Canvas drawing library integration, batch processing, advanced image customization

For detailed requirements analysis, see [REQUIREMENTS_COMPLIANCE.md](./REQUIREMENTS_COMPLIANCE.md).

## ÔøΩüõ†Ô∏è Technology Stack

### Backend
- **Flask** - Web framework
- **SpeechRecognition** - Voice processing (Google Speech API + Web Speech API)
- **Transformers** - NLP and concept extraction
- **OpenAI API** - DALL-E 3 image generation
- **Stable Diffusion** - Alternative image generation
- **MongoDB** - Session storage (optional)
- **WebSockets** - Real-time communication

### Frontend
- **React.js** - User interface
- **Socket.io** - Real-time updates
- **RecordRTC** - Audio recording
- **Web Speech API** - Browser-based speech recognition
- **Axios** - API communication

## üìñ Usage Examples

### Voice Commands
- *"Draw a sunny beach with palm trees and a boat on the water"*
- *"Create a sketch of a mountain landscape at sunset"*
- *"Generate a cartoon character of a friendly robot"*
- *"Paint a watercolor of a city skyline at night"*

### Text Input
You can also type descriptions instead of speaking:
- Technical diagrams and flowcharts
- Architectural sketches
- Character concepts for stories
- Educational illustrations

## Customization

### Image Styles
- **Realistic** - Photographic quality
- **Illustration** - Digital art style
- **Cartoon** - Animated/comic style  
- **Sketch** - Hand-drawn appearance
- **Painting** - Artistic brush strokes
- **Watercolor** - Soft, flowing colors

### Image Sizes
- 256√ó256 pixels (fast generation)
- 512√ó512 pixels (balanced)
- 1024√ó1024 pixels (high quality)

## üîß Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for DALL-E | Optional* |
| `GOOGLE_APPLICATION_CREDENTIALS` | Google Cloud credentials | Optional* |
| `MONGODB_URI` | MongoDB connection string | Optional |
| `FLASK_ENV` | Flask environment (development/production) | No |
| `PORT` | Server port (default: 5000) | No |

*At least one AI service must be configured

### Audio Settings
The system supports various audio formats and automatically adjusts for:
- Noise cancellation
- Echo reduction  
- Sample rate optimization
- Microphone sensitivity

## üß™ Development

### Running in Development Mode

```bash
# Backend with hot reload
flask run --debug

# Frontend with hot reload
cd frontend && npm start
```

### Testing

```bash
# Run backend tests
python -m pytest tests/

# Run frontend tests
cd frontend && npm test
```

### Building for Production

```bash
# Build frontend
cd frontend && npm run build

# Set production environment
export FLASK_ENV=production

# Run with Gunicorn
gunicorn --bind 0.0.0.0:5000 app:app
```

##  Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up --build
```

##  Performance

- **Speech Recognition**: < 2 seconds
- **Image Generation**: 3-10 seconds (depending on model)
- **Total Processing**: 5-12 seconds end-to-end
- **Supported Languages**: English (primary), expandable
- **Concurrent Users**: Up to 50 (with proper scaling)

##  Limitations

- Currently optimized for English language input
- Handles one visual concept per sentence optimally
- Image quality depends on selected AI model
- Requires internet connection for cloud-based AI services
- Processing time varies based on server load

##  Future Enhancements

- [ ] **Multi-language Support** - Support for Spanish, French, German
- [ ] **Mobile App** - Native iOS and Android applications
- [ ] **Collaborative Mode** - Real-time collaborative sketching
- [ ] **Voice Filters** - Background noise reduction
- [ ] **Custom Models** - Domain-specific image generation
- [ ] **Batch Processing** - Multiple images from single description
- [ ] **Export Options** - SVG, PDF, high-resolution formats
- [ ] **Integration APIs** - Embed in other applications

##  Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Support

- **Documentation**: [Wiki](https://github.com/yourusername/echosketch/wiki)
- **Issues**: [GitHub Issues](https://github.com/yourusername/echosketch/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/echosketch/discussions)
- **Email**: echosketch-support@yourcompany.com

##  Acknowledgments

- OpenAI for DALL-E API
- Google for Speech-to-Text services
- Stability AI for Stable Diffusion
- HuggingFace for transformer models
- The open-source community for various libraries

---

**Built with for accessible creativity**

*Transform your voice into visuals with ECHOSKETCH - where words become art!*
